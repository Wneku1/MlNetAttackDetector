{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4bbb574d",
   "metadata": {
    "id": "KLfj50LPPFDB",
    "papermill": {
     "duration": 0.039734,
     "end_time": "2022-01-17T21:40:45.200404",
     "exception": false,
     "start_time": "2022-01-17T21:40:45.160670",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Check input files\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "45c7690a",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2022-01-17T21:40:45.288137Z",
     "iopub.status.busy": "2022-01-17T21:40:45.287373Z",
     "iopub.status.idle": "2022-01-17T21:40:45.300617Z",
     "shell.execute_reply": "2022-01-17T21:40:45.301186Z",
     "shell.execute_reply.started": "2022-01-17T21:30:49.103682Z"
    },
    "id": "KlegH6X6PFDK",
    "papermill": {
     "duration": 0.061317,
     "end_time": "2022-01-17T21:40:45.301538",
     "exception": false,
     "start_time": "2022-01-17T21:40:45.240221",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "datasets/Wednesday-14-02-2018_TrafficForML_CICFlowMeter.csv\n",
      "datasets/Thursday-15-02-2018_TrafficForML_CICFlowMeter.csv\n",
      "datasets/Friday-23-02-2018_TrafficForML_CICFlowMeter.csv\n",
      "datasets/Thuesday-20-02-2018_TrafficForML_CICFlowMeter.csv\n",
      "datasets/Wednesday-21-02-2018_TrafficForML_CICFlowMeter.csv\n",
      "datasets/Thursday-01-03-2018_TrafficForML_CICFlowMeter.csv\n",
      "datasets/Friday-16-02-2018_TrafficForML_CICFlowMeter.csv\n",
      "datasets/Thursday-22-02-2018_TrafficForML_CICFlowMeter.csv\n",
      "datasets/Wednesday-28-02-2018_TrafficForML_CICFlowMeter.csv\n",
      "datasets/Friday-02-03-2018_TrafficForML_CICFlowMeter.csv\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "for dirname, _, filenames in os.walk('datasets'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ca25baa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_dtype_to_int(x):\n",
    "    if not x:\n",
    "        return np.nan\n",
    "    try:\n",
    "        return int(x)\n",
    "    except:\n",
    "        return np.nan\n",
    "\n",
    "\n",
    "def convert_dtype_to_float(x):\n",
    "    if not x:\n",
    "        return np.nan\n",
    "    try:\n",
    "        return float(x)\n",
    "    except:\n",
    "        return np.nan\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3aa3de62",
   "metadata": {
    "id": "VNwBYC2aH9UF",
    "papermill": {
     "duration": 0.038369,
     "end_time": "2022-01-17T21:40:45.378612",
     "exception": false,
     "start_time": "2022-01-17T21:40:45.340243",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Import train data and create DataFrame object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7dc2ecfd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-17T21:40:45.462008Z",
     "iopub.status.busy": "2022-01-17T21:40:45.461151Z",
     "iopub.status.idle": "2022-01-17T21:40:45.514670Z",
     "shell.execute_reply": "2022-01-17T21:40:45.514023Z",
     "shell.execute_reply.started": "2022-01-17T21:30:49.116444Z"
    },
    "id": "rPzgqJfuH88j",
    "papermill": {
     "duration": 0.098772,
     "end_time": "2022-01-17T21:40:45.514849",
     "exception": false,
     "start_time": "2022-01-17T21:40:45.416077",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The files have been imported\n"
     ]
    }
   ],
   "source": [
    "rawsData = pd.read_csv('datasets/Wednesday-14-02-2018_TrafficForML_CICFlowMeter.csv',\n",
    "                       converters={'Dst Port': convert_dtype_to_int,\n",
    "                                   'Protocol': convert_dtype_to_int,\n",
    "                                   'Flow Duration': convert_dtype_to_int,\n",
    "                                   'Tot Fwd Pkts': convert_dtype_to_int,\n",
    "                                   'Tot Bwd Pkts': convert_dtype_to_int,\n",
    "                                   'TotLen Fwd Pkts': convert_dtype_to_int,\n",
    "                                   'TotLen Bwd Pkts': convert_dtype_to_int,\n",
    "                                   'Fwd Pkt Len Max': convert_dtype_to_int,\n",
    "                                   'Fwd Pkt Len Min': convert_dtype_to_int,\n",
    "                                   'Fwd Pkt Len Mean': convert_dtype_to_float,\n",
    "                                   'Fwd Pkt Len Std': convert_dtype_to_float,\n",
    "                                   'Bwd Pkt Len Max': convert_dtype_to_int,\n",
    "                                   'Bwd Pkt Len Min': convert_dtype_to_int,\n",
    "                                   'Bwd Pkt Len Mean': convert_dtype_to_float,\n",
    "                                   'Bwd Pkt Len Std': convert_dtype_to_float,\n",
    "                                   'Flow Byts/s': convert_dtype_to_float,\n",
    "                                   'Flow Pkts/s': convert_dtype_to_float,\n",
    "                                   'Flow IAT Mean': convert_dtype_to_float,\n",
    "                                   'Flow IAT Std': convert_dtype_to_float,\n",
    "                                   'Flow IAT Max': convert_dtype_to_int,\n",
    "                                   'Flow IAT Min': convert_dtype_to_int,\n",
    "                                   'Fwd IAT Tot': convert_dtype_to_int,\n",
    "                                   'Fwd IAT Mean': convert_dtype_to_float,\n",
    "                                   'Fwd IAT Std': convert_dtype_to_float,\n",
    "                                   'Fwd IAT Max': convert_dtype_to_int,\n",
    "                                   'Fwd IAT Min': convert_dtype_to_int,\n",
    "                                   'Bwd IAT Tot': convert_dtype_to_int,\n",
    "                                   'Bwd IAT Mean': convert_dtype_to_float,\n",
    "                                   'Bwd IAT Std': convert_dtype_to_float,\n",
    "                                   'Bwd IAT Max': convert_dtype_to_int,\n",
    "                                   'Bwd IAT Min': convert_dtype_to_int,\n",
    "                                   'Fwd PSH Flags': convert_dtype_to_int,\n",
    "                                   'Bwd PSH Flags': convert_dtype_to_int,\n",
    "                                   'Fwd URG Flags': convert_dtype_to_int,\n",
    "                                   'Bwd URG Flags': convert_dtype_to_int,\n",
    "                                   'Fwd Header Len': convert_dtype_to_int,\n",
    "                                   'Bwd Header Len': convert_dtype_to_int,\n",
    "                                   'Fwd Pkts/s': convert_dtype_to_float,\n",
    "                                   'Bwd Pkts/s': convert_dtype_to_float,\n",
    "                                   'Pkt Len Min': convert_dtype_to_int,\n",
    "                                   'Pkt Len Max': convert_dtype_to_int,\n",
    "                                   'Pkt Len Mean': convert_dtype_to_float,\n",
    "                                   'Pkt Len Std': convert_dtype_to_float,\n",
    "                                   'Pkt Len Var': convert_dtype_to_float,\n",
    "                                   'FIN Flag Cnt': convert_dtype_to_int,\n",
    "                                   'SYN Flag Cnt': convert_dtype_to_int,\n",
    "                                   'RST Flag Cnt': convert_dtype_to_int,\n",
    "                                   'PSH Flag Cnt': convert_dtype_to_int,\n",
    "                                   'ACK Flag Cnt': convert_dtype_to_int,\n",
    "                                   'URG Flag Cnt': convert_dtype_to_int,\n",
    "                                   'CWE Flag Count': convert_dtype_to_int,\n",
    "                                   'ECE Flag Cnt': convert_dtype_to_int,\n",
    "                                   'Down/Up Ratio': convert_dtype_to_int,\n",
    "                                   'Pkt Size Avg': convert_dtype_to_float,\n",
    "                                   'Fwd Seg Size Avg': convert_dtype_to_float,\n",
    "                                   'Bwd Seg Size Avg': convert_dtype_to_float,\n",
    "                                   'Fwd Byts/b Avg': convert_dtype_to_int,\n",
    "                                   'Fwd Pkts/b Avg': convert_dtype_to_int,\n",
    "                                   'Fwd Blk Rate Avg': convert_dtype_to_int,\n",
    "                                   'Bwd Byts/b Avg': convert_dtype_to_int,\n",
    "                                   'Bwd Pkts/b Avg': convert_dtype_to_int,\n",
    "                                   'Bwd Blk Rate Avg': convert_dtype_to_int,\n",
    "                                   'Subflow Fwd Pkts': convert_dtype_to_int,\n",
    "                                   'Subflow Fwd Byts': convert_dtype_to_int,\n",
    "                                   'Subflow Bwd Pkts': convert_dtype_to_int,\n",
    "                                   'Subflow Bwd Byts': convert_dtype_to_int,\n",
    "                                   'Init Fwd Win Byts': convert_dtype_to_int,\n",
    "                                   'Init Bwd Win Byts': convert_dtype_to_int,\n",
    "                                   'Fwd Act Data Pkts': convert_dtype_to_int,\n",
    "                                   'Fwd Seg Size Min': convert_dtype_to_int,\n",
    "                                   'Active Mean': convert_dtype_to_float,\n",
    "                                   'Active Std': convert_dtype_to_float,\n",
    "                                   'Active Max': convert_dtype_to_int,\n",
    "                                   'Active Min': convert_dtype_to_int,\n",
    "                                   'Idle Mean': convert_dtype_to_float,\n",
    "                                   'Idle Std': convert_dtype_to_float,\n",
    "                                   'Idle Max': convert_dtype_to_int,\n",
    "                                   'Idle Min': convert_dtype_to_int})\n",
    "\n",
    "print(\"The files have been imported\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c8981180",
   "metadata": {},
   "outputs": [],
   "source": [
    "columnsToDrop = [\n",
    "    'Flow Pkts/s',\n",
    "    'Timestamp',\n",
    "    'Active Max',\n",
    "    'Active Min',\n",
    "    'Active Std',\n",
    "    'Bwd IAT Max',\n",
    "    'Bwd IAT Min',\n",
    "    'Bwd IAT Std',\n",
    "    'Bwd IAT Tot',\n",
    "    'Bwd Pkt Len Max',\n",
    "    'Bwd Pkt Len Min',\n",
    "    'Bwd Pkt Len Std',\n",
    "    'Flow IAT Max',\n",
    "    'Flow IAT Min',\n",
    "    'Flow IAT Std',\n",
    "    'Fwd IAT Max',\n",
    "    'Fwd IAT Min',\n",
    "    'Fwd IAT Std',\n",
    "    'Fwd IAT Tot',\n",
    "    'Fwd Pkt Len Max',\n",
    "    'Fwd Pkt Len Min',\n",
    "    'Fwd Pkt Len Std',\n",
    "    'Idle Max',\n",
    "    'Idle Min',\n",
    "    'Idle Std',\n",
    "    'Pkt Len Max',\n",
    "    'Pkt Len Min',\n",
    "    'Pkt Len Std']\n",
    "\n",
    "rawsData = rawsData.drop(columnsToDrop, axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fe159507",
   "metadata": {},
   "outputs": [],
   "source": [
    "LABEL = 'Label'\n",
    "NORMAL = 'Benign'\n",
    "FTP = 'FTP-BruteForce'\n",
    "SSH = 'SSH-Bruteforce'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2eabc0fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "rawNormal = rawsData[rawsData[LABEL] == NORMAL]\n",
    "rawFTP = rawsData[rawsData[LABEL] == FTP]\n",
    "rawSSH = rawsData[rawsData[LABEL] == SSH]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d760ac04",
   "metadata": {},
   "outputs": [],
   "source": [
    "from operator import itemgetter\n",
    "\n",
    "FEATURE = 'Feature'\n",
    "COUNT = 'Count'\n",
    "\n",
    "\n",
    "def getNotDuplicatedFeatures(data):\n",
    "    result = []\n",
    "    for column in data.keys():\n",
    "        feature = data[column]\n",
    "        feature = feature.drop_duplicates()\n",
    "        result.append({FEATURE: column, COUNT: feature.shape[0]})\n",
    "    return sorted(result, key=itemgetter(COUNT), reverse=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e26a1905",
   "metadata": {},
   "outputs": [],
   "source": [
    "def specialPrint(data):\n",
    "    for feature in data:\n",
    "        print('{0:17}  {1}'.format(feature[FEATURE], feature[COUNT]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1851d5bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "countedRawNormal = getNotDuplicatedFeatures(rawNormal)\n",
    "countedRawSSH = getNotDuplicatedFeatures(rawFTP)\n",
    "countedRawFTP = getNotDuplicatedFeatures(rawSSH)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "abb2de6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Flow Byts/s        372377\n",
      "Flow IAT Mean      341347\n",
      "Fwd Pkts/s         339725\n",
      "Flow Duration      333735\n",
      "Fwd IAT Mean       300433\n",
      "Bwd Pkts/s         292606\n",
      "Bwd IAT Mean       238666\n",
      "Idle Mean          80419\n",
      "Active Mean        73591\n",
      "Pkt Len Var        42646\n",
      "Pkt Len Mean       35996\n",
      "Pkt Size Avg       35646\n",
      "Bwd Pkt Len Mean   24518\n",
      "Bwd Seg Size Avg   24517\n",
      "Dst Port           18567\n",
      "Fwd Pkt Len Mean   17847\n",
      "Fwd Seg Size Avg   17847\n",
      "TotLen Bwd Pkts    15656\n",
      "Subflow Bwd Byts   15656\n",
      "TotLen Fwd Pkts    5842\n",
      "Subflow Fwd Byts   5842\n",
      "Init Bwd Win Byts  3547\n",
      "Init Fwd Win Byts  3308\n",
      "Bwd Header Len     1843\n",
      "Fwd Header Len     1237\n",
      "Tot Bwd Pkts       988\n",
      "Subflow Bwd Pkts   988\n",
      "Tot Fwd Pkts       751\n",
      "Subflow Fwd Pkts   751\n",
      "Fwd Act Data Pkts  112\n",
      "Down/Up Ratio      33\n",
      "Fwd Seg Size Min   10\n",
      "Protocol           3\n",
      "Fwd PSH Flags      2\n",
      "FIN Flag Cnt       2\n",
      "SYN Flag Cnt       2\n",
      "RST Flag Cnt       2\n",
      "PSH Flag Cnt       2\n",
      "ACK Flag Cnt       2\n",
      "URG Flag Cnt       2\n",
      "ECE Flag Cnt       2\n",
      "Bwd PSH Flags      1\n",
      "Fwd URG Flags      1\n",
      "Bwd URG Flags      1\n",
      "CWE Flag Count     1\n",
      "Fwd Byts/b Avg     1\n",
      "Fwd Pkts/b Avg     1\n",
      "Fwd Blk Rate Avg   1\n",
      "Bwd Byts/b Avg     1\n",
      "Bwd Pkts/b Avg     1\n",
      "Bwd Blk Rate Avg   1\n",
      "Label              1\n"
     ]
    }
   ],
   "source": [
    "specialPrint(countedRawNormal)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "40a0e43c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Flow Duration      54\n",
      "Flow IAT Mean      54\n",
      "Fwd Pkts/s         54\n",
      "Bwd Pkts/s         54\n",
      "Flow Byts/s        2\n",
      "Dst Port           1\n",
      "Protocol           1\n",
      "Tot Fwd Pkts       1\n",
      "Tot Bwd Pkts       1\n",
      "TotLen Fwd Pkts    1\n",
      "TotLen Bwd Pkts    1\n",
      "Fwd Pkt Len Mean   1\n",
      "Bwd Pkt Len Mean   1\n",
      "Fwd IAT Mean       1\n",
      "Bwd IAT Mean       1\n",
      "Fwd PSH Flags      1\n",
      "Bwd PSH Flags      1\n",
      "Fwd URG Flags      1\n",
      "Bwd URG Flags      1\n",
      "Fwd Header Len     1\n",
      "Bwd Header Len     1\n",
      "Pkt Len Mean       1\n",
      "Pkt Len Var        1\n",
      "FIN Flag Cnt       1\n",
      "SYN Flag Cnt       1\n",
      "RST Flag Cnt       1\n",
      "PSH Flag Cnt       1\n",
      "ACK Flag Cnt       1\n",
      "URG Flag Cnt       1\n",
      "CWE Flag Count     1\n",
      "ECE Flag Cnt       1\n",
      "Down/Up Ratio      1\n",
      "Pkt Size Avg       1\n",
      "Fwd Seg Size Avg   1\n",
      "Bwd Seg Size Avg   1\n",
      "Fwd Byts/b Avg     1\n",
      "Fwd Pkts/b Avg     1\n",
      "Fwd Blk Rate Avg   1\n",
      "Bwd Byts/b Avg     1\n",
      "Bwd Pkts/b Avg     1\n",
      "Bwd Blk Rate Avg   1\n",
      "Subflow Fwd Pkts   1\n",
      "Subflow Fwd Byts   1\n",
      "Subflow Bwd Pkts   1\n",
      "Subflow Bwd Byts   1\n",
      "Init Fwd Win Byts  1\n",
      "Init Bwd Win Byts  1\n",
      "Fwd Act Data Pkts  1\n",
      "Fwd Seg Size Min   1\n",
      "Active Mean        1\n",
      "Idle Mean          1\n",
      "Label              1\n"
     ]
    }
   ],
   "source": [
    "specialPrint(countedRawSSH)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a6d9fed2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Flow Byts/s        82092\n",
      "Flow IAT Mean      79070\n",
      "Fwd IAT Mean       75752\n",
      "Fwd Pkts/s         74998\n",
      "Bwd IAT Mean       72023\n",
      "Bwd Pkts/s         71499\n",
      "Flow Duration      59000\n",
      "Pkt Len Var        98\n",
      "Pkt Len Mean       77\n",
      "Pkt Size Avg       77\n",
      "Fwd Pkt Len Mean   70\n",
      "Fwd Seg Size Avg   70\n",
      "Fwd Header Len     15\n",
      "Tot Fwd Pkts       14\n",
      "Subflow Fwd Pkts   14\n",
      "TotLen Fwd Pkts    10\n",
      "Subflow Fwd Byts   10\n",
      "Bwd Header Len     9\n",
      "Tot Bwd Pkts       8\n",
      "Subflow Bwd Pkts   8\n",
      "Bwd Pkt Len Mean   7\n",
      "Bwd Seg Size Avg   7\n",
      "Init Bwd Win Byts  4\n",
      "TotLen Bwd Pkts    3\n",
      "Subflow Bwd Byts   3\n",
      "Fwd Act Data Pkts  3\n",
      "Dst Port           2\n",
      "PSH Flag Cnt       2\n",
      "ACK Flag Cnt       2\n",
      "URG Flag Cnt       2\n",
      "Down/Up Ratio      2\n",
      "Init Fwd Win Byts  2\n",
      "Fwd Seg Size Min   2\n",
      "Protocol           1\n",
      "Fwd PSH Flags      1\n",
      "Bwd PSH Flags      1\n",
      "Fwd URG Flags      1\n",
      "Bwd URG Flags      1\n",
      "FIN Flag Cnt       1\n",
      "SYN Flag Cnt       1\n",
      "RST Flag Cnt       1\n",
      "CWE Flag Count     1\n",
      "ECE Flag Cnt       1\n",
      "Fwd Byts/b Avg     1\n",
      "Fwd Pkts/b Avg     1\n",
      "Fwd Blk Rate Avg   1\n",
      "Bwd Byts/b Avg     1\n",
      "Bwd Pkts/b Avg     1\n",
      "Bwd Blk Rate Avg   1\n",
      "Active Mean        1\n",
      "Idle Mean          1\n",
      "Label              1\n"
     ]
    }
   ],
   "source": [
    "specialPrint(countedRawFTP)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaf1c860",
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.graph_objs as go\n",
    "from plotly.offline import init_notebook_mode, iplot\n",
    "init_notebook_mode(connected=True)\n",
    "\n",
    "\n",
    "def showAttackDistribution(data):\n",
    "    counted = data.value_counts()\n",
    "\n",
    "    fig = go.Figure(data=[\n",
    "        go.Bar(name=NORMAL,\n",
    "               y=[counted[NORMAL]],\n",
    "               x=[NORMAL],\n",
    "               text=str(counted[NORMAL]),\n",
    "               orientation='v',\n",
    "               textposition='outside',),\n",
    "        go.Bar(name=FTP,\n",
    "               y=[counted[FTP]],\n",
    "               x=[FTP],\n",
    "               text=str(counted[FTP]),\n",
    "               orientation='v',\n",
    "               textposition='outside',),\n",
    "        go.Bar(name=SSH,\n",
    "               y=[counted[SSH]],\n",
    "               x=[SSH],\n",
    "               text=str(counted[SSH]),\n",
    "               orientation='v',\n",
    "               textposition='outside',)\n",
    "    ])\n",
    "    # Change the bar mode\n",
    "    fig.update_layout(\n",
    "        width=1600,\n",
    "        height=1200,\n",
    "        title=f'Labels distribution',\n",
    "        yaxis_title='<b>Number of packets<b>',\n",
    "        xaxis_title='<b>Packet type<b>',\n",
    "        font=dict(size=32))\n",
    "    fig.update_layout(showlegend=False)\n",
    "    iplot(fig)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0687c881",
   "metadata": {},
   "outputs": [],
   "source": [
    "showAttackDistribution(rawsData['Label'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bf0fc3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "selectedFeatures = [\n",
    "    'Flow IAT Mean',\n",
    "    'Fwd Pkts/s',\n",
    "    'Flow Duration',\n",
    "    'Flow Byts/s',\n",
    "    'Fwd IAT Mean',\n",
    "    'Bwd Pkts/s',\n",
    "    'Bwd IAT Mean',\n",
    "    'Idle Mean',\n",
    "    'Active Mean',\n",
    "    'Pkt Len Var',\n",
    "    'Pkt Len Mean',\n",
    "    'Pkt Size Avg',\n",
    "    'Bwd Pkt Len Mean',\n",
    "    'TotLen Bwd Pkts',\n",
    "    'Bwd Seg Size Avg',\n",
    "    'Subflow Bwd Byts',\n",
    "    'Fwd Pkt Len Mean',\n",
    "    'Dst Port',\n",
    "    'Fwd Seg Size Avg',\n",
    "    'TotLen Fwd Pkts',\n",
    "    'Subflow Fwd Byts',\n",
    "    'Tot Fwd Pkts',\n",
    "    'Fwd Header Len',\n",
    "    'Subflow Fwd Pkts',\n",
    "    'Fwd Act Data Pkts',\n",
    "    'Label'\n",
    "]\n",
    "\n",
    "selectedFeatures = list(set(selectedFeatures))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7767c903",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getSliceFromRawData():\n",
    "    return rawsData[selectedFeatures].copy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38df5297",
   "metadata": {},
   "outputs": [],
   "source": [
    "selectedData = getSliceFromRawData()\n",
    "allDatasetToTest = getSliceFromRawData()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c51e0cd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "withoutDuplicates = selectedData.drop_duplicates().copy()\n",
    "withoutDuplicates.info()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65640cd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "showAttackDistribution(withoutDuplicates[LABEL])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51a59d37",
   "metadata": {},
   "outputs": [],
   "source": [
    "def shortData(data, benignCount, ftpCount, sshCount):\n",
    "    shortedNormal = data[data[LABEL] ==\n",
    "                         NORMAL].sample(benignCount, ignore_index=True, random_state=32)\n",
    "    shortedFTP = data[data[LABEL] == FTP].sample(\n",
    "        ftpCount, ignore_index=True, random_state=32)\n",
    "    shortedSSH = data[data[LABEL] == SSH].sample(\n",
    "        sshCount, ignore_index=True, random_state=32)\n",
    "    return pd.concat([shortedNormal, shortedFTP, shortedSSH], axis=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "941ce6dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "toTrainModel = shortData(withoutDuplicates, 109000, 27, 47000).copy()\n",
    "selectedToSaveDataset = shortData(withoutDuplicates, 200000, 54, 94039).copy()\n",
    "showAttackDistribution(toTrainModel[LABEL])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66ed06f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def makeOnlyAttackOrNot(dataToTransform):\n",
    "    dataToTransform[LABEL] = dataToTransform[LABEL].map(\n",
    "        lambda i: 0 if i == NORMAL else 1)\n",
    "    return dataToTransform\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b45f69d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "toTrainModel = makeOnlyAttackOrNot(toTrainModel)\n",
    "selectedToSaveDataset = makeOnlyAttackOrNot(selectedToSaveDataset)\n",
    "allDatasetToTest = makeOnlyAttackOrNot(allDatasetToTest)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb8d8751",
   "metadata": {},
   "outputs": [],
   "source": [
    "def removeNanInf(data):\n",
    "    data.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "    data.dropna(inplace=True)\n",
    "    return data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7616c18f",
   "metadata": {},
   "outputs": [],
   "source": [
    "toTrainModel = removeNanInf(toTrainModel)\n",
    "allDatasetToTest = removeNanInf(allDatasetToTest)\n",
    "selectedToSaveDataset = removeNanInf(selectedToSaveDataset)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5beb66e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "\n",
    "# def scale(dataToTransform, columntoTransform):\n",
    "\n",
    "#     ss_dict = {col: StandardScaler() for col in columntoTransform}\n",
    "\n",
    "#     for colKey in columntoTransform:\n",
    "#         dataToTransform[colKey] = ss_dict[colKey].fit_transform(\n",
    "#             np.array(dataToTransform[colKey]).reshape(-1, 1))\n",
    "\n",
    "#     return dataToTransform\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "594ae099",
   "metadata": {},
   "outputs": [],
   "source": [
    "# numericColumntoTransform = withoutDuplicates.keys()\n",
    "# withoutDuplicates = scale(withoutDuplicates, numericColumntoTransform)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4e93444",
   "metadata": {
    "id": "xYzsVX21PFDc",
    "papermill": {
     "duration": 0.047639,
     "end_time": "2022-01-17T21:40:48.282094",
     "exception": false,
     "start_time": "2022-01-17T21:40:48.234455",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Heatmap\n",
    "#### Heatmap provide us information on how much the individual features are interpedent. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5d3cba8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-17T21:40:48.370987Z",
     "iopub.status.busy": "2022-01-17T21:40:48.370237Z",
     "iopub.status.idle": "2022-01-17T21:40:51.265700Z",
     "shell.execute_reply": "2022-01-17T21:40:51.266249Z",
     "shell.execute_reply.started": "2022-01-17T21:30:49.408211Z"
    },
    "id": "ObQ1AkeKPFDf",
    "papermill": {
     "duration": 2.938931,
     "end_time": "2022-01-17T21:40:51.266450",
     "exception": false,
     "start_time": "2022-01-17T21:40:48.327519",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "f, ax = plt.subplots(figsize=(32, 18))\n",
    "hmap = sns.heatmap(abs(toTrainModel.corr()), annot=True,\n",
    "                   linewidths=0.5, fmt='.2f', ax=ax, annot_kws={\"fontsize\": 21})\n",
    "\n",
    "for label in hmap.get_yticklabels():\n",
    "    label.set_size(25)\n",
    "    label.set_weight(\"bold\")\n",
    "\n",
    "for label in hmap.get_xticklabels():\n",
    "    label.set_size(27)\n",
    "    label.set_weight(\"bold\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9222e1a",
   "metadata": {},
   "source": [
    "Save label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e38865a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = toTrainModel[LABEL]\n",
    "toTrainModel = toTrainModel.drop([LABEL], axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1e7b0ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "def printNanFinite(data):\n",
    "    print('Is any Nan:', np.any(np.isnan(data)))\n",
    "    print('Is all finite:', np.all(np.isfinite(data)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93c2a848",
   "metadata": {},
   "outputs": [],
   "source": [
    "printNanFinite(toTrainModel)\n",
    "print('\\n')\n",
    "printNanFinite(allDatasetToTest)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97355b3a",
   "metadata": {},
   "source": [
    "Scale numeric values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f11a5dcb",
   "metadata": {},
   "source": [
    "#### After preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4403bf33",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    toTrainModel, labels, test_size=0.33, random_state=32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d1f63a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "isRFC = True\n",
    "isMLPC = False\n",
    "isSequential = False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "958a0a7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "\n",
    "\n",
    "def model():\n",
    "    if isRFC:\n",
    "        model = RandomForestClassifier(\n",
    "            n_estimators=100, max_depth=5, min_samples_leaf=4)\n",
    "    elif isMLPC:\n",
    "        model = MLPClassifier(random_state=32)\n",
    "    else:\n",
    "        model = Sequential([\n",
    "            Dense(256, activation='softplus', kernel_initializer='glorot_uniform',\n",
    "                  input_dim=X_train.shape[1]),\n",
    "            Dense(128, activation='softplus',\n",
    "                  kernel_initializer='glorot_uniform'),\n",
    "            Dense(1, kernel_initializer='glorot_uniform', activation='sigmoid')\n",
    "        ])\n",
    "\n",
    "        model.compile(loss='binary_crossentropy',\n",
    "                      optimizer='Adam')\n",
    "\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a71aa012",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23f2432f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a069fe42",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "\n",
    "\n",
    "def confMatrix(yTrain, xTrainPreds, yTest, xTestPreds):\n",
    "    # Your code here\n",
    "    cmTrain = confusion_matrix(yTrain, xTrainPreds)\n",
    "    X_train_disp = ConfusionMatrixDisplay(confusion_matrix=cmTrain)\n",
    "\n",
    "    cmTest = confusion_matrix(yTest, xTestPreds)\n",
    "    X_test_disp = ConfusionMatrixDisplay(confusion_matrix=cmTest)\n",
    "    # End\n",
    "\n",
    "    _, ax = plt.subplots(1, 2, figsize=(10, 5), dpi=150)\n",
    "\n",
    "    X_train_disp.plot(ax=ax[0])\n",
    "    ax[0].set_title(\"Train\")\n",
    "\n",
    "    X_test_disp.plot(ax=ax[1])\n",
    "    ax[1].set_title(\"Test\")\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d991ff69",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score, accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "\n",
    "def printScores(name, labels, predicts):\n",
    "    print(name)\n",
    "    print('Accuracy: %.3f ' % accuracy_score(labels, predicts))\n",
    "    print('Precision: %.3f ' % precision_score(labels, predicts))\n",
    "    print('Recall: %.3f' % recall_score(labels, predicts))\n",
    "    print('F1 Score: %.3f' % f1_score(labels, predicts))\n",
    "    print('\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab898d8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_preds = model.predict(X_train)\n",
    "X_test_preds = model.predict(X_test)\n",
    "\n",
    "if isSequential:\n",
    "    print('Train auc:', roc_auc_score(y_train, X_train_preds))\n",
    "    print('Test auc:', roc_auc_score(y_test, X_test_preds))\n",
    "else:\n",
    "    printScores('Train:', y_train, X_train_preds)\n",
    "    printScores('Test:', y_test, X_test_preds)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1a07fb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "confMatrix(y_train, X_train_preds, y_test, X_test_preds)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8def0c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "allDatasetLabels = allDatasetToTest[LABEL]\n",
    "allDatasetToTest = allDatasetToTest.drop([LABEL], axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14299dee",
   "metadata": {},
   "outputs": [],
   "source": [
    "AllDatasetPreds = model.predict(allDatasetToTest)\n",
    "\n",
    "if isSequential:\n",
    "    print('Auc:', roc_auc_score(allDatasetLabels, AllDatasetPreds))\n",
    "else:\n",
    "    printScores('All dataset:', allDatasetLabels, AllDatasetPreds)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c57150c",
   "metadata": {},
   "outputs": [],
   "source": [
    "allDatasetConfusionMatrix = confusion_matrix(allDatasetLabels, AllDatasetPreds)\n",
    "allDataSetMatrixDisplay = ConfusionMatrixDisplay(\n",
    "    confusion_matrix=allDatasetConfusionMatrix)\n",
    "_, ax = plt.subplots(figsize=(8, 4), dpi=130)\n",
    "ax.set_title(\"All dataset\")\n",
    "allDataSetMatrixDisplay.plot(ax=ax)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30881c1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "selectedToSaveDataset.to_csv('ftp_ssh_brute_force.csv')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 42.965214,
   "end_time": "2022-01-17T21:41:16.495863",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2022-01-17T21:40:33.530649",
   "version": "2.3.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
