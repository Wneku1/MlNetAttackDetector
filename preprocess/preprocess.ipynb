{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4bbb574d",
   "metadata": {
    "id": "KLfj50LPPFDB",
    "papermill": {
     "duration": 0.039734,
     "end_time": "2022-01-17T21:40:45.200404",
     "exception": false,
     "start_time": "2022-01-17T21:40:45.160670",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Check input files\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "45c7690a",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2022-01-17T21:40:45.288137Z",
     "iopub.status.busy": "2022-01-17T21:40:45.287373Z",
     "iopub.status.idle": "2022-01-17T21:40:45.300617Z",
     "shell.execute_reply": "2022-01-17T21:40:45.301186Z",
     "shell.execute_reply.started": "2022-01-17T21:30:49.103682Z"
    },
    "id": "KlegH6X6PFDK",
    "papermill": {
     "duration": 0.061317,
     "end_time": "2022-01-17T21:40:45.301538",
     "exception": false,
     "start_time": "2022-01-17T21:40:45.240221",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../datasets/Wednesday-14-02-2018_TrafficForML_CICFlowMeter.csv\n",
      "../datasets/Thursday-15-02-2018_TrafficForML_CICFlowMeter.csv\n",
      "../datasets/Friday-23-02-2018_TrafficForML_CICFlowMeter.csv\n",
      "../datasets/Thuesday-20-02-2018_TrafficForML_CICFlowMeter.csv\n",
      "../datasets/Wednesday-21-02-2018_TrafficForML_CICFlowMeter.csv\n",
      "../datasets/Thursday-01-03-2018_TrafficForML_CICFlowMeter.csv\n",
      "../datasets/Friday-16-02-2018_TrafficForML_CICFlowMeter.csv\n",
      "../datasets/Thursday-22-02-2018_TrafficForML_CICFlowMeter.csv\n",
      "../datasets/Wednesday-28-02-2018_TrafficForML_CICFlowMeter.csv\n",
      "../datasets/Friday-02-03-2018_TrafficForML_CICFlowMeter.csv\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "for dirname, _, filenames in os.walk('../datasets'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "bd6b8d4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def readDrop(path):\n",
    "    data = pd.read_csv(path)\n",
    "    data = data.drop(['Timestamp'], axis=1)\n",
    "    data = data.drop_duplicates()\n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3aa3de62",
   "metadata": {
    "id": "VNwBYC2aH9UF",
    "papermill": {
     "duration": 0.038369,
     "end_time": "2022-01-17T21:40:45.378612",
     "exception": false,
     "start_time": "2022-01-17T21:40:45.340243",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Import train data and create DataFrame object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7dc2ecfd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-17T21:40:45.462008Z",
     "iopub.status.busy": "2022-01-17T21:40:45.461151Z",
     "iopub.status.idle": "2022-01-17T21:40:45.514670Z",
     "shell.execute_reply": "2022-01-17T21:40:45.514023Z",
     "shell.execute_reply.started": "2022-01-17T21:30:49.116444Z"
    },
    "id": "rPzgqJfuH88j",
    "papermill": {
     "duration": 0.098772,
     "end_time": "2022-01-17T21:40:45.514849",
     "exception": false,
     "start_time": "2022-01-17T21:40:45.416077",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The files have been imported\n"
     ]
    }
   ],
   "source": [
    "# rawsData = pd.read_csv('../datasets/firstDataset.csv')\n",
    "\n",
    "ftpSshBruteForce = pd.read_csv(\n",
    "    '../datasets/Wednesday-14-02-2018_TrafficForML_CICFlowMeter.csv').drop_duplicates()\n",
    "# dosHttpHulk = pd.read_csv(\n",
    "#     '../datasets/Friday-16-02-2018_TrafficForML_CICFlowMeter.csv')\n",
    "# ddosHttpUdp = pd.read_csv(\n",
    "#     '../datasets/Thuesday-20-02-2018_TrafficForML_CICFlowMeter.csv')\n",
    "# ddosLoicHoic = pd.read_csv(\n",
    "#     '../datasets/Wednesday-21-02-2018_TrafficForML_CICFlowMeter.csv')\n",
    "# webXSSBruteForceSql = pd.read_csv(\n",
    "#     '../datasets/Thursday-22-02-2018_TrafficForML_CICFlowMeter.csv')\n",
    "# webXSSBruteForceSql_2 = pd.read_csv(\n",
    "#     '../datasets/Friday-23-02-2018_TrafficForML_CICFlowMeter.csv')\n",
    "# infiltration = pd.read_csv(\n",
    "#     '../datasets/Wednesday-28-02-2018_TrafficForML_CICFlowMeter.csv')\n",
    "# infiltration_2 = pd.read_csv(\n",
    "#     '../datasets/Thursday-01-03-2018_TrafficForML_CICFlowMeter.csv')\n",
    "# bot = pd.read_csv(\n",
    "#     '../datasets/Friday-02-03-2018_TrafficForML_CICFlowMeter.csv')\n",
    "\n",
    "print(\"The files have been imported\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "339c917d",
   "metadata": {},
   "outputs": [],
   "source": [
    "dosGoldeyeSlowloris = readDrop(\n",
    "    '../datasets/Thursday-15-02-2018_TrafficForML_CICFlowMeter.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e2ace67f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "884658"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dosGoldeyeSlowloris.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "da080912",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "822947"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ftpSshBruteForce.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "843a078e",
   "metadata": {},
   "outputs": [],
   "source": [
    "rawsData = pd.concat([ftpSshBruteForce, dosGoldeyeSlowloris, dosHttpHulk, ddosHttpUdp, ddosLoicHoic,\n",
    "                       webXSSBruteForceSql, webXSSBruteForceSql_2, infiltration, infiltration_2, bot], axis=0).drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8981180",
   "metadata": {},
   "outputs": [],
   "source": [
    "rawsData = rawsData.drop(['Timestamp'], axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb9e6b00",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(rawsData)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d50713c",
   "metadata": {},
   "outputs": [],
   "source": [
    "rawsData.keys()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe159507",
   "metadata": {},
   "outputs": [],
   "source": [
    "LABEL = 'Label'\n",
    "NORMAL = 'Benign'\n",
    "FTP = 'FTP-BruteForce'\n",
    "SSH = 'SSH-Bruteforce'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2eabc0fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# rawNormal = rawsData[rawsData[LABEL] == NORMAL]\n",
    "# rawFTP = rawsData[rawsData[LABEL] == FTP]\n",
    "# rawSSH = rawsData[rawsData[LABEL] == SSH]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaf1c860",
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.graph_objs as go\n",
    "from plotly.offline import init_notebook_mode, iplot\n",
    "# import plotly as py\n",
    "# import plotly.express as px\n",
    "init_notebook_mode(connected=True)\n",
    "\n",
    "\n",
    "def showAttackDistribution(data):\n",
    "    counted = data.value_counts()\n",
    "\n",
    "    fig = go.Figure(data=[\n",
    "        go.Bar(name=NORMAL,\n",
    "               y=[counted[NORMAL]],\n",
    "               x=[NORMAL],\n",
    "               text=str(counted[NORMAL]),\n",
    "               orientation='v',\n",
    "               textposition='outside',),\n",
    "        go.Bar(name=FTP,\n",
    "               y=[counted[FTP]],\n",
    "               x=[FTP],\n",
    "               text=str(counted[FTP]),\n",
    "               orientation='v',\n",
    "               textposition='outside',),\n",
    "        go.Bar(name=SSH,\n",
    "               y=[counted[SSH]],\n",
    "               x=[SSH],\n",
    "               text=str(counted[SSH]),\n",
    "               orientation='v',\n",
    "               textposition='outside',)\n",
    "    ])\n",
    "    # Change the bar mode\n",
    "    fig.update_layout(\n",
    "        width=800,\n",
    "        height=600,\n",
    "        title=f'Labels Distribution',\n",
    "        yaxis_title='Number of attacks',\n",
    "        xaxis_title='Attack Name',)\n",
    "    iplot(fig)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0687c881",
   "metadata": {},
   "outputs": [],
   "source": [
    "showAttackDistribution(rawsData['Label'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7767c903",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getSliceFromRawData():\n",
    "    return rawsData[['Protocol',\n",
    "                     'Fwd Pkt Len Max',\n",
    "                     'Fwd Pkt Len Max',\n",
    "                     'Bwd Pkt Len Mean',\n",
    "                     'Fwd Pkt Len Std',\n",
    "                     'Bwd Pkt Len Max',\n",
    "                     'Bwd Pkt Len Min',\n",
    "                     'Bwd Pkt Len Std',\n",
    "                     'Bwd IAT Tot',\n",
    "                     'Bwd IAT Mean',\n",
    "                     'Bwd IAT Max',\n",
    "                     'Pkt Len Min',\n",
    "                     'Pkt Len Max',\n",
    "                     'PSH Flag Cnt',\n",
    "                     'Fwd Header Len',\n",
    "                     'SYN Flag Cnt',\n",
    "                     'RST Flag Cnt',\n",
    "                     'ACK Flag Cnt',\n",
    "                     'URG Flag Cnt',\n",
    "                     'ECE Flag Cnt',\n",
    "                     'Fwd Seg Size Avg',\n",
    "                     'Init Fwd Win Byts',\n",
    "                     'Fwd Act Data Pkts',\n",
    "                     'Fwd Seg Size Min',\n",
    "                     'Down/Up Ratio',\n",
    "                     'Bwd Pkts/s',\n",
    "                     'Fwd Pkts/s',\n",
    "                     'Pkt Size Avg',\n",
    "                     'Idle Mean',\n",
    "                     'Label']].copy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38df5297",
   "metadata": {},
   "outputs": [],
   "source": [
    "selectedData = getSliceFromRawData()\n",
    "allDatasetToTest = getSliceFromRawData()\n",
    "\n",
    "# selectedData = rawsData.copy()\n",
    "# allDatasetToTest = rawsData.copy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c51e0cd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "withoutDuplicates = selectedData.drop_duplicates().copy()\n",
    "withoutDuplicates.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65640cd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "showAttackDistribution(withoutDuplicates[LABEL])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51a59d37",
   "metadata": {},
   "outputs": [],
   "source": [
    "def shortData(data, featureName):\n",
    "    shortedNormal = data[data[featureName] ==\n",
    "                         NORMAL].sample(100, ignore_index=True, random_state=32)\n",
    "    shortedFTP = data[data[featureName] == FTP].sample(10, ignore_index=True, random_state=32)\n",
    "    shortedSSH = data[data[featureName] == SSH].sample(100, ignore_index=True, random_state=32)\n",
    "    return pd.concat([shortedNormal, shortedFTP, shortedSSH], axis=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "941ce6dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "toTrainModel = shortData(withoutDuplicates, LABEL).copy()\n",
    "showAttackDistribution(toTrainModel[LABEL])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66ed06f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def makeOnlyAttackOrNot(dataToTransform):\n",
    "    columnToTransform = [LABEL]\n",
    "    for colKey in columnToTransform:\n",
    "        dataToTransform[colKey] = dataToTransform[colKey].map(\n",
    "            lambda i: 0 if i == NORMAL else 1)\n",
    "        # dataToTransform[colKey] = LabelEncoder().fit_transform(dataToTransform[colKey])\n",
    "\n",
    "    return dataToTransform\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b45f69d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "toTrainModel = makeOnlyAttackOrNot(toTrainModel)\n",
    "allDatasetToTest = makeOnlyAttackOrNot(allDatasetToTest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb8d8751",
   "metadata": {},
   "outputs": [],
   "source": [
    "def removeNanInf(data):\n",
    "    maxNonInf = data.max().loc[lambda value: value < np.Inf].max()\n",
    "    data = data.replace(np.nan, 0)\n",
    "    data = data.replace(np.inf, maxNonInf)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7616c18f",
   "metadata": {},
   "outputs": [],
   "source": [
    "toTrainModel = removeNanInf(toTrainModel)\n",
    "allDatasetToTest = removeNanInf(allDatasetToTest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5beb66e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "\n",
    "# def scale(dataToTransform, columntoTransform):\n",
    "\n",
    "#     ss_dict = {col: StandardScaler() for col in columntoTransform}\n",
    "\n",
    "#     for colKey in columntoTransform:\n",
    "#         dataToTransform[colKey] = ss_dict[colKey].fit_transform(\n",
    "#             np.array(dataToTransform[colKey]).reshape(-1, 1))\n",
    "\n",
    "#     return dataToTransform\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "594ae099",
   "metadata": {},
   "outputs": [],
   "source": [
    "# numericColumntoTransform = withoutDuplicates.keys()\n",
    "# withoutDuplicates = scale(withoutDuplicates, numericColumntoTransform)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4e93444",
   "metadata": {
    "id": "xYzsVX21PFDc",
    "papermill": {
     "duration": 0.047639,
     "end_time": "2022-01-17T21:40:48.282094",
     "exception": false,
     "start_time": "2022-01-17T21:40:48.234455",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Heatmap\n",
    "#### Heatmap provide us information on how much the individual features are interpedent. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5d3cba8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-17T21:40:48.370987Z",
     "iopub.status.busy": "2022-01-17T21:40:48.370237Z",
     "iopub.status.idle": "2022-01-17T21:40:51.265700Z",
     "shell.execute_reply": "2022-01-17T21:40:51.266249Z",
     "shell.execute_reply.started": "2022-01-17T21:30:49.408211Z"
    },
    "id": "ObQ1AkeKPFDf",
    "papermill": {
     "duration": 2.938931,
     "end_time": "2022-01-17T21:40:51.266450",
     "exception": false,
     "start_time": "2022-01-17T21:40:48.327519",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "f, ax = plt.subplots(figsize=(15, 8))\n",
    "sns.heatmap(abs(toTrainModel.corr()), annot=True,\n",
    "            linewidths=0.5, fmt='.2f', ax=ax)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9222e1a",
   "metadata": {},
   "source": [
    "Save label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e38865a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = toTrainModel[LABEL]\n",
    "toTrainModel = toTrainModel.drop([LABEL], axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1e7b0ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "def printNanFinite(data):\n",
    "    print('Is any Nan:', np.any(np.isnan(data)))\n",
    "    print('Is all finite:', np.all(np.isfinite(data)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93c2a848",
   "metadata": {},
   "outputs": [],
   "source": [
    "printNanFinite(toTrainModel)\n",
    "print('\\n')\n",
    "printNanFinite(allDatasetToTest)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97355b3a",
   "metadata": {},
   "source": [
    "Scale numeric values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f11a5dcb",
   "metadata": {},
   "source": [
    "#### After preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4403bf33",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    toTrainModel, labels, test_size=0.33, random_state=32)\n",
    "\n",
    "\n",
    "X_train.to_csv('X_train.csv')\n",
    "X_test.to_csv('X_test.csv')\n",
    "y_train.to_csv('y_train.csv')\n",
    "y_test.to_csv('y_test.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d1f63a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "isRFC = True\n",
    "isMLPC = False\n",
    "isSequential = False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "958a0a7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "\n",
    "\n",
    "def model():\n",
    "    if isRFC:\n",
    "        model = RandomForestClassifier(\n",
    "            n_estimators=100, max_depth=5, min_samples_leaf=4)\n",
    "    elif isMLPC:\n",
    "        model = MLPClassifier(random_state=32)\n",
    "    else:\n",
    "        model = Sequential([\n",
    "            Dense(256, activation='softplus', kernel_initializer='glorot_uniform',\n",
    "                  input_dim=X_train.shape[1]),\n",
    "            Dense(128, activation='softplus',\n",
    "                  kernel_initializer='glorot_uniform'),\n",
    "            Dense(1, kernel_initializer='glorot_uniform', activation='sigmoid')\n",
    "        ])\n",
    "\n",
    "        model.compile(loss='binary_crossentropy',\n",
    "                      optimizer='Adam')\n",
    "\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a71aa012",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23f2432f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a069fe42",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "\n",
    "def confMatrix(yTrain, xTrainPreds, yTest, xTestPreds):\n",
    "    # Your code here\n",
    "    cmTrain = confusion_matrix(yTrain, xTrainPreds)\n",
    "    X_train_disp = ConfusionMatrixDisplay(confusion_matrix=cmTrain)\n",
    "\n",
    "    cmTest = confusion_matrix(yTest, xTestPreds)\n",
    "    X_test_disp = ConfusionMatrixDisplay(confusion_matrix=cmTest)\n",
    "    # End\n",
    "\n",
    "    _, ax = plt.subplots(1, 2, figsize=(10, 5), dpi=150)\n",
    "\n",
    "    X_train_disp.plot(ax=ax[0])\n",
    "    ax[0].set_title(\"Train\")\n",
    "\n",
    "    X_test_disp.plot(ax=ax[1])\n",
    "    ax[1].set_title(\"Test\")\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d991ff69",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score, accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "def printScores(name, labels, predicts):\n",
    "    print(name )\n",
    "    print('Accuracy: %.3f ' % accuracy_score(labels, predicts))\n",
    "    print('Precision: %.3f ' % precision_score(labels, predicts))\n",
    "    print('Recall: %.3f' % recall_score(labels, predicts))\n",
    "    print('F1 Score: %.3f' % f1_score(labels, predicts))\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab898d8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "X_train_preds = model.predict(X_train)\n",
    "X_test_preds = model.predict(X_test)\n",
    "\n",
    "if isSequential:\n",
    "    print('Train auc:', roc_auc_score(y_train, X_train_preds))\n",
    "    print('Test auc:', roc_auc_score(y_test, X_test_preds))\n",
    "else:\n",
    "    printScores('Train:', y_train, X_train_preds)\n",
    "    printScores('Test:', y_test, X_test_preds)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1a07fb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "confMatrix(y_train, X_train_preds, y_test, X_test_preds)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8def0c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "allDatasetLabels = allDatasetToTest[LABEL]\n",
    "allDatasetToTest = allDatasetToTest.drop([LABEL], axis=1)\n",
    "\n",
    "allDatasetLabels.to_csv('allDatasetLabels.csv')\n",
    "allDatasetToTest.to_csv('allDatasetToTest.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14299dee",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "AllDatasetPreds = model.predict(allDatasetToTest)\n",
    "\n",
    "if isSequential:\n",
    "    print('Auc:', roc_auc_score(allDatasetLabels, AllDatasetPreds))\n",
    "else:\n",
    "    printScores('All dataset:', allDatasetLabels, AllDatasetPreds)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c57150c",
   "metadata": {},
   "outputs": [],
   "source": [
    "allDatasetConfusionMatrix = confusion_matrix(allDatasetLabels, AllDatasetPreds)\n",
    "allDataSetMatrixDisplay = ConfusionMatrixDisplay(confusion_matrix=allDatasetConfusionMatrix)\n",
    "_, ax = plt.subplots(figsize=(8, 4), dpi=130)\n",
    "ax.set_title(\"All dataset\")\n",
    "allDataSetMatrixDisplay.plot(ax=ax)\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 42.965214,
   "end_time": "2022-01-17T21:41:16.495863",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2022-01-17T21:40:33.530649",
   "version": "2.3.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
