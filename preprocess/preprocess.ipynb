{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4bbb574d",
   "metadata": {
    "id": "KLfj50LPPFDB",
    "papermill": {
     "duration": 0.039734,
     "end_time": "2022-01-17T21:40:45.200404",
     "exception": false,
     "start_time": "2022-01-17T21:40:45.160670",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Check input files\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45c7690a",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2022-01-17T21:40:45.288137Z",
     "iopub.status.busy": "2022-01-17T21:40:45.287373Z",
     "iopub.status.idle": "2022-01-17T21:40:45.300617Z",
     "shell.execute_reply": "2022-01-17T21:40:45.301186Z",
     "shell.execute_reply.started": "2022-01-17T21:30:49.103682Z"
    },
    "id": "KlegH6X6PFDK",
    "papermill": {
     "duration": 0.061317,
     "end_time": "2022-01-17T21:40:45.301538",
     "exception": false,
     "start_time": "2022-01-17T21:40:45.240221",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "pathToDataset = ''\n",
    "\n",
    "for dirname, _, filenames in os.walk('datasets'):\n",
    "    for filename in filenames:\n",
    "        pathToDataset = os.path.join(dirname, filename)\n",
    "        print(pathToDataset)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3aa3de62",
   "metadata": {
    "id": "VNwBYC2aH9UF",
    "papermill": {
     "duration": 0.038369,
     "end_time": "2022-01-17T21:40:45.378612",
     "exception": false,
     "start_time": "2022-01-17T21:40:45.340243",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Import train data and create DataFrame object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dc2ecfd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-17T21:40:45.462008Z",
     "iopub.status.busy": "2022-01-17T21:40:45.461151Z",
     "iopub.status.idle": "2022-01-17T21:40:45.514670Z",
     "shell.execute_reply": "2022-01-17T21:40:45.514023Z",
     "shell.execute_reply.started": "2022-01-17T21:30:49.116444Z"
    },
    "id": "rPzgqJfuH88j",
    "papermill": {
     "duration": 0.098772,
     "end_time": "2022-01-17T21:40:45.514849",
     "exception": false,
     "start_time": "2022-01-17T21:40:45.416077",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "rawsData = pd.read_csv(pathToDataset)\n",
    "\n",
    "print(\"The files have been imported\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8981180",
   "metadata": {},
   "outputs": [],
   "source": [
    "rawsData = rawsData.drop(['Timestamp'], axis=1)  # doesn't matter\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe159507",
   "metadata": {},
   "outputs": [],
   "source": [
    "LABEL = 'Label'\n",
    "NORMAL = 'Benign'\n",
    "FTP = 'FTP-BruteForce'\n",
    "SSH = 'SSH-Bruteforce'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2eabc0fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "rawNormal = rawsData[rawsData[LABEL] == NORMAL]\n",
    "rawFTP = rawsData[rawsData[LABEL] == FTP]\n",
    "rawSSH = rawsData[rawsData[LABEL] == SSH]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d760ac04",
   "metadata": {},
   "outputs": [],
   "source": [
    "from operator import itemgetter\n",
    "\n",
    "FEATURE = 'Feature'\n",
    "COUNT = 'Count'\n",
    "\n",
    "\n",
    "def getNotDuplicatedFeatures(data):\n",
    "    result = []\n",
    "    for column in data.keys():\n",
    "        feature = data[column]\n",
    "        feature = feature.drop_duplicates()\n",
    "        result.append({FEATURE: column, COUNT: feature.shape[0]})\n",
    "    return sorted(result, key=itemgetter(COUNT), reverse=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e26a1905",
   "metadata": {},
   "outputs": [],
   "source": [
    "def specialPrint(data):\n",
    "    for feature in data:\n",
    "        print('{0:17}  {1}'.format(feature[FEATURE], feature[COUNT]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1851d5bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "countedRawNormal = getNotDuplicatedFeatures(rawNormal)\n",
    "countedRawSSH = getNotDuplicatedFeatures(rawFTP)\n",
    "countedRawFTP = getNotDuplicatedFeatures(rawSSH)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abb2de6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "specialPrint(countedRawNormal)\n",
    "# Flow Byts/s        372377 v flow byte rate that is number of packets transferred per second\n",
    "# Flow Pkts/s        341908 x flow packets rate that is number of packets transferred per second because it is very similar to Flow Byts/s\n",
    "# Flow IAT Mean      341347 v Average time between two flows\n",
    "# Fwd Pkts/s         339725 v Number of forward packets per second\n",
    "# Flow Duration      333735 v Flow duration\n",
    "# Flow IAT Std       322849 x Standard deviation similar to Flow IAT Mean\n",
    "# Fwd IAT Mean       300433 v Average size of packet in forward direction\n",
    "# Fwd IAT Tot        296550 x Total time between two packets sent in the forward direction\n",
    "# Bwd Pkts/s         292606 v Number of backward packets per second\n",
    "# Fwd IAT Max        255430 x Maximum time between two packets sent in the forward direction because I have Fwd IAT Mean\n",
    "# Flow IAT Max       247903 x Maximum time between two packets sent in the forward direction because I have Flow IAT Mean\n",
    "# Fwd IAT Std        247713 x Standard deviation time between two packets sent in the forward direction because I have Fwd IAT Mean\n",
    "# Bwd IAT Mean       238666 v Mean time between two packets sent in the backward direction\n",
    "# Bwd IAT Std        236571 x Standard deviation time between two packets sent in the backward direction because I have Bwd IAT Mean\n",
    "# Bwd IAT Tot        236287 x Total time between two packets sent in the backward direction because I have Bwd IAT Mean\n",
    "# Bwd IAT Max        168641 x Maximum time between two packets sent in the backward direction because I have Bwd IAT Mean\n",
    "# Bwd IAT Min        108796 x Minimum time between two packets sent in the backward direction because I have Bwd IAT Mean\n",
    "# Fwd IAT Min        89617  x Minimum time between two packets sent in the forward direction because I have Fwd IAT Mean\n",
    "# Idle Mean          80419  v Mean time a flow was idle before becoming active\n",
    "# Active Mean        73591  v Mean time a flow was active before becoming idle\n",
    "# Active Max         71437  x Maximum time a flow was active before becoming idle because I have Active Mean\n",
    "# Idle Min           69046  x Minimum time a flow was idle before becoming active because I have Idle Mean\n",
    "# Flow IAT Min       66506  x Minimum time between two flows because I have Flow IAT Mean\n",
    "# Idle Max           59134  x Maximum time a flow was idle before becoming active because I have Idle Mean\n",
    "# Idle Std           57847  x Standard deviation time a flow was idle before becoming active because I have Idle Mean\n",
    "# Active Std         55382  x Standard deviation time a flow was active before becoming idle because I have Active Mean\n",
    "# Pkt Len Var        42646  v Minimum inter-arrival time of packet\n",
    "# Pkt Len Std        42505  v Standard deviation length of a flow\n",
    "# Active Min         38864  x Minimum time a flow was active before becoming idle because I have Active Mean\n",
    "# Pkt Len Mean       35996  x Mean length of a flow because I have Pkt Len Std\n",
    "# Pkt Size Avg       35646  v Average size of packet\n",
    "# Bwd Pkt Len Std    28860  v Standard deviation size of packet in backward direction\n",
    "# Fwd Pkt Len Std    27425  v Standard deviation size of packet in forward direction\n",
    "# Bwd Pkt Len Mean   24518  x Mean size of packet in backward direction because I have Active Mean Bwd Pkt Len Std\n",
    "# Bwd Seg Size Avg   24517  x Average size observed in the backward direction because I have Pkt Size Avg\n",
    "# Dst Port           18567  x Destination Port\n",
    "# Fwd Pkt Len Mean   17847  x Average size of packet in forward direction because I have Pkt Size Avg Pkt Len Std\n",
    "# Fwd Seg Size Avg   17847  x Average size observed in the forward direction because I have Pkt Size Avg\n",
    "# TotLen Bwd Pkts    15656  v Total packets in the backward direction because\n",
    "# Subflow Bwd Byts   15656  v The average number of bytes in a sub flow in the backward direction because\n",
    "# TotLen Fwd Pkts    5842   v Total packets in the forward direction\n",
    "# Subflow Fwd Byts   5842   v The average number of bytes in a sub flow in the forward direction\n",
    "# Init Bwd Win Byts  3547   x Not enough unique values\n",
    "# Init Fwd Win Byts  3308   x Not enough unique values\n",
    "# Bwd Header Len     1843   x Not enough unique values\n",
    "# Fwd Pkt Len Max    1390   x Not enough unique values\n",
    "# Fwd Header Len     1237   x Not enough unique values\n",
    "# Pkt Len Max        1139   x Not enough unique values\n",
    "# Tot Bwd Pkts       988    x Not enough unique values\n",
    "# Subflow Bwd Pkts   988    x Not enough unique values\n",
    "# Bwd Pkt Len Max    958    x Not enough unique values\n",
    "# Tot Fwd Pkts       751    x Not enough unique values\n",
    "# Subflow Fwd Pkts   751    x Not enough unique values\n",
    "# Bwd Pkt Len Min    270    x Not enough unique values\n",
    "# Fwd Pkt Len Min    112    x Not enough unique values\n",
    "# Fwd Act Data Pkts  112    x Not enough unique values\n",
    "# Pkt Len Min        80     x Not enough unique values\n",
    "# Down/Up Ratio      33     x Not enough unique values\n",
    "# Fwd Seg Size Min   10     x Not enough unique values\n",
    "# Protocol           3      x Not enough unique values\n",
    "# Fwd PSH Flags      2      x Not enough unique values\n",
    "# FIN Flag Cnt       2      x Not enough unique values\n",
    "# SYN Flag Cnt       2      x Not enough unique values\n",
    "# RST Flag Cnt       2      x Not enough unique values\n",
    "# PSH Flag Cnt       2      x Not enough unique values\n",
    "# ACK Flag Cnt       2      x Not enough unique values\n",
    "# URG Flag Cnt       2      x Not enough unique values\n",
    "# ECE Flag Cnt       2      x Not enough unique values\n",
    "# Bwd PSH Flags      1      x Not enough unique values\n",
    "# Fwd URG Flags      1      x Not enough unique values\n",
    "# Bwd URG Flags      1      x Not enough unique values\n",
    "# CWE Flag Count     1      x Not enough unique values\n",
    "# Fwd Byts/b Avg     1      x Not enough unique values\n",
    "# Fwd Pkts/b Avg     1      x Not enough unique values\n",
    "# Fwd Blk Rate Avg   1      x Not enough unique values\n",
    "# Bwd Byts/b Avg     1      x Not enough unique values\n",
    "# Bwd Pkts/b Avg     1      x Not enough unique values\n",
    "# Bwd Blk Rate Avg   1      x Not enough unique values\n",
    "# Label              1      v\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40a0e43c",
   "metadata": {},
   "outputs": [],
   "source": [
    "specialPrint(countedRawSSH)\n",
    "# Flow Duration      54 v\n",
    "# Flow Pkts/s        54 v\n",
    "# Flow IAT Mean      54 v\n",
    "# Flow IAT Max       54 v\n",
    "# Flow IAT Min       54 v\n",
    "# Fwd Pkts/s         54 v\n",
    "# Bwd Pkts/s         54 v\n",
    "# Flow Byts/s        2  x\n",
    "# Dst Port           1  x\n",
    "# Protocol           1  x\n",
    "# Tot Fwd Pkts       1  x\n",
    "# Tot Bwd Pkts       1  x\n",
    "# TotLen Fwd Pkts    1  x\n",
    "# TotLen Bwd Pkts    1  x\n",
    "# Fwd Pkt Len Max    1  x\n",
    "# Fwd Pkt Len Min    1  x\n",
    "# Fwd Pkt Len Mean   1  x\n",
    "# Fwd Pkt Len Std    1  x\n",
    "# Bwd Pkt Len Max    1  x\n",
    "# Bwd Pkt Len Min    1  x\n",
    "# Bwd Pkt Len Mean   1  x\n",
    "# Bwd Pkt Len Std    1  x\n",
    "# Flow IAT Std       1  x\n",
    "# Fwd IAT Tot        1  x\n",
    "# Fwd IAT Mean       1  x\n",
    "# Fwd IAT Std        1  x\n",
    "# Fwd IAT Max        1  x\n",
    "# Fwd IAT Min        1  x\n",
    "# Bwd IAT Tot        1  x\n",
    "# Bwd IAT Mean       1  x\n",
    "# Bwd IAT Std        1  x\n",
    "# Bwd IAT Max        1  x\n",
    "# Bwd IAT Min        1  x\n",
    "# Fwd PSH Flags      1  x\n",
    "# Bwd PSH Flags      1  x\n",
    "# Fwd URG Flags      1  x\n",
    "# Bwd URG Flags      1  x\n",
    "# Fwd Header Len     1  x\n",
    "# Bwd Header Len     1  x\n",
    "# Pkt Len Min        1  x\n",
    "# Pkt Len Max        1  x\n",
    "# Pkt Len Mean       1  x\n",
    "# Pkt Len Std        1  x\n",
    "# Pkt Len Var        1  x\n",
    "# FIN Flag Cnt       1  x\n",
    "# SYN Flag Cnt       1  x\n",
    "# RST Flag Cnt       1  x\n",
    "# PSH Flag Cnt       1  x\n",
    "# ACK Flag Cnt       1  x\n",
    "# URG Flag Cnt       1  x\n",
    "# CWE Flag Count     1  x\n",
    "# ECE Flag Cnt       1  x\n",
    "# Down/Up Ratio      1  x\n",
    "# Pkt Size Avg       1  x\n",
    "# Fwd Seg Size Avg   1  x\n",
    "# Bwd Seg Size Avg   1  x\n",
    "# Fwd Byts/b Avg     1  x\n",
    "# Fwd Pkts/b Avg     1  x\n",
    "# Fwd Blk Rate Avg   1  x\n",
    "# Bwd Byts/b Avg     1  x\n",
    "# Bwd Pkts/b Avg     1  x\n",
    "# Bwd Blk Rate Avg   1  x\n",
    "# Subflow Fwd Pkts   1  x\n",
    "# Subflow Fwd Byts   1  x\n",
    "# Subflow Bwd Pkts   1  x\n",
    "# Subflow Bwd Byts   1  x\n",
    "# Init Fwd Win Byts  1  x\n",
    "# Init Bwd Win Byts  1  x\n",
    "# Fwd Act Data Pkts  1  x\n",
    "# Fwd Seg Size Min   1  x\n",
    "# Active Mean        1  x\n",
    "# Active Std         1  x\n",
    "# Active Max         1  x\n",
    "# Active Min         1  x\n",
    "# Idle Mean          1  x\n",
    "# Idle Std           1  x\n",
    "# Idle Max           1  x\n",
    "# Idle Min           1  x\n",
    "# Label              1  v\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6d9fed2",
   "metadata": {},
   "outputs": [],
   "source": [
    "specialPrint(countedRawFTP)\n",
    "# Flow IAT Std       93937 v\n",
    "# Fwd IAT Std        93819 v\n",
    "# Bwd IAT Std        93819 v\n",
    "# Flow Byts/s        82092 v\n",
    "# Flow IAT Mean      79070 v\n",
    "# Flow Pkts/s        78634 v\n",
    "# Fwd IAT Mean       75752 v\n",
    "# Fwd Pkts/s         74998 v\n",
    "# Bwd IAT Mean       72023 v\n",
    "# Bwd Pkts/s         71499 v\n",
    "# Flow IAT Max       64573 v\n",
    "# Fwd IAT Max        63957 v\n",
    "# Bwd IAT Max        62720 v\n",
    "# Fwd IAT Tot        59068 v\n",
    "# Flow Duration      59000 v\n",
    "# Bwd IAT Tot        58807 v\n",
    "# Fwd IAT Min        518   x\n",
    "# Bwd IAT Min        109   x\n",
    "# Pkt Len Var        98    x\n",
    "# Pkt Len Std        86    x\n",
    "# Fwd Pkt Len Std    77    x\n",
    "# Pkt Len Mean       77    x\n",
    "# Pkt Size Avg       77    x\n",
    "# Fwd Pkt Len Mean   70    x\n",
    "# Fwd Seg Size Avg   70    x\n",
    "# Flow IAT Min       43    x\n",
    "# Fwd Header Len     15    x\n",
    "# Tot Fwd Pkts       14    x\n",
    "# Subflow Fwd Pkts   14    x\n",
    "# TotLen Fwd Pkts    10    x\n",
    "# Subflow Fwd Byts   10    x\n",
    "# Bwd Header Len     9     x\n",
    "# Tot Bwd Pkts       8     x\n",
    "# Subflow Bwd Pkts   8     x\n",
    "# Bwd Pkt Len Mean   7     x\n",
    "# Bwd Pkt Len Std    7     x\n",
    "# Bwd Seg Size Avg   7     x\n",
    "# Init Bwd Win Byts  4     x\n",
    "# TotLen Bwd Pkts    3     x\n",
    "# Subflow Bwd Byts   3     x\n",
    "# Fwd Act Data Pkts  3     x\n",
    "# Dst Port           2     x\n",
    "# Fwd Pkt Len Max    2     x\n",
    "# Bwd Pkt Len Max    2     x\n",
    "# Pkt Len Max        2     x\n",
    "# PSH Flag Cnt       2     x\n",
    "# ACK Flag Cnt       2     x\n",
    "# URG Flag Cnt       2     x\n",
    "# Down/Up Ratio      2     x\n",
    "# Init Fwd Win Byts  2     x\n",
    "# Fwd Seg Size Min   2     x\n",
    "# Protocol           1     x\n",
    "# Fwd Pkt Len Min    1     x\n",
    "# Bwd Pkt Len Min    1     x\n",
    "# Fwd PSH Flags      1     x\n",
    "# Bwd PSH Flags      1     x\n",
    "# Fwd URG Flags      1     x\n",
    "# Bwd URG Flags      1     x\n",
    "# Pkt Len Min        1     x\n",
    "# FIN Flag Cnt       1     x\n",
    "# SYN Flag Cnt       1     x\n",
    "# RST Flag Cnt       1     x\n",
    "# CWE Flag Count     1     x\n",
    "# ECE Flag Cnt       1     x\n",
    "# Fwd Byts/b Avg     1     x\n",
    "# Fwd Pkts/b Avg     1     x\n",
    "# Fwd Blk Rate Avg   1     x\n",
    "# Bwd Byts/b Avg     1     x\n",
    "# Bwd Pkts/b Avg     1     x\n",
    "# Bwd Blk Rate Avg   1     x\n",
    "# Active Mean        1     x\n",
    "# Active Std         1     x\n",
    "# Active Max         1     x\n",
    "# Active Min         1     x\n",
    "# Idle Mean          1     x\n",
    "# Idle Std           1     x\n",
    "# Idle Max           1     x\n",
    "# Idle Min           1     x\n",
    "# Label              1     v\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaf1c860",
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.graph_objs as go\n",
    "from plotly.offline import init_notebook_mode, iplot\n",
    "init_notebook_mode(connected=True)\n",
    "\n",
    "\n",
    "def showAttackDistribution(data):\n",
    "    counted = data.value_counts()\n",
    "\n",
    "    fig = go.Figure(data=[\n",
    "        go.Bar(name=NORMAL,\n",
    "               y=[counted[NORMAL]],\n",
    "               x=[NORMAL],\n",
    "               text=str(counted[NORMAL]),\n",
    "               orientation='v',\n",
    "               textposition='outside',),\n",
    "        go.Bar(name=FTP,\n",
    "               y=[counted[FTP]],\n",
    "               x=[FTP],\n",
    "               text=str(counted[FTP]),\n",
    "               orientation='v',\n",
    "               textposition='outside',),\n",
    "        go.Bar(name=SSH,\n",
    "               y=[counted[SSH]],\n",
    "               x=[SSH],\n",
    "               text=str(counted[SSH]),\n",
    "               orientation='v',\n",
    "               textposition='outside',)\n",
    "    ])\n",
    "    # Change the bar mode\n",
    "    fig.update_layout(\n",
    "        width=800,\n",
    "        height=600,\n",
    "        title=f'Labels Distribution',\n",
    "        yaxis_title='Number of attacks',\n",
    "        xaxis_title='Attack Name',)\n",
    "    iplot(fig)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0687c881",
   "metadata": {},
   "outputs": [],
   "source": [
    "showAttackDistribution(rawsData['Label'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bf0fc3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "selectedFeatures = [\n",
    "    # Selected from Benign\n",
    "    'Flow Byts/s',\n",
    "    'Flow IAT Mean',\n",
    "    'Fwd Pkts/s',\n",
    "    'Flow Duration',\n",
    "    'Fwd IAT Mean',\n",
    "    'Bwd Pkts/s',\n",
    "    'Bwd IAT Mean',\n",
    "    'Idle Mean',\n",
    "    'Active Mean',\n",
    "    'Pkt Len Var',\n",
    "    'Pkt Len Std',\n",
    "    'Pkt Size Avg',\n",
    "    'Bwd Pkt Len Std',\n",
    "    'Fwd Pkt Len Std',\n",
    "    'TotLen Bwd Pkts',\n",
    "    'Subflow Bwd Byts',\n",
    "    'TotLen Fwd Pkts',\n",
    "    'Subflow Fwd Byts',\n",
    "    'Label',\n",
    "    # Selected from SSH\n",
    "    'Flow Duration',\n",
    "    'Flow Pkts/s',\n",
    "    'Flow IAT Mean',\n",
    "    'Flow IAT Max',\n",
    "    'Flow IAT Min',\n",
    "    'Fwd Pkts/s',\n",
    "    'Bwd Pkts/s',\n",
    "    # Selected from FTP\n",
    "    'Flow IAT Std',\n",
    "    'Fwd IAT Std',\n",
    "    'Bwd IAT Std',\n",
    "    'Flow Byts/s',\n",
    "    'Flow IAT Mean',\n",
    "    'Flow Pkts/s',\n",
    "    'Fwd IAT Mean',\n",
    "    'Fwd Pkts/s',\n",
    "    'Bwd IAT Mean',\n",
    "    'Bwd Pkts/s',\n",
    "    'Flow IAT Max',\n",
    "    'Fwd IAT Max',\n",
    "    'Bwd IAT Max',\n",
    "    'Fwd IAT Tot',\n",
    "    'Flow Duration',\n",
    "    'Bwd IAT Tot'\n",
    "]\n",
    "\n",
    "print(len(selectedFeatures))\n",
    "\n",
    "selectedFeatures = list(set(selectedFeatures))\n",
    "\n",
    "print(len(selectedFeatures))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7767c903",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getSliceFromRawData():\n",
    "    return rawsData[selectedFeatures].copy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38df5297",
   "metadata": {},
   "outputs": [],
   "source": [
    "selectedData = getSliceFromRawData()\n",
    "allDatasetToTest = getSliceFromRawData()\n",
    "\n",
    "# selectedData = rawsData.copy()\n",
    "# allDatasetToTest = rawsData.copy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c51e0cd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "withoutDuplicates = selectedData.drop_duplicates().copy()\n",
    "withoutDuplicates.info()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65640cd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "showAttackDistribution(withoutDuplicates[LABEL])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51a59d37",
   "metadata": {},
   "outputs": [],
   "source": [
    "def shortData(data, featureName):\n",
    "    shortedNormal = data[data[featureName] ==\n",
    "                         NORMAL].sample(109000, ignore_index=True, random_state=32)\n",
    "    shortedFTP = data[data[featureName] == FTP].sample(\n",
    "        27, ignore_index=True, random_state=32)\n",
    "    shortedSSH = data[data[featureName] == SSH].sample(\n",
    "        47000, ignore_index=True, random_state=32)\n",
    "    return pd.concat([shortedNormal, shortedFTP, shortedSSH], axis=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "941ce6dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "toTrainModel = shortData(withoutDuplicates, LABEL).copy()\n",
    "showAttackDistribution(toTrainModel[LABEL])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66ed06f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def makeOnlyAttackOrNot(dataToTransform):\n",
    "    columnToTransform = [LABEL]\n",
    "    for colKey in columnToTransform:\n",
    "        dataToTransform[colKey] = dataToTransform[colKey].map(\n",
    "            lambda i: 0 if i == NORMAL else 1)\n",
    "        # dataToTransform[colKey] = LabelEncoder().fit_transform(dataToTransform[colKey])\n",
    "\n",
    "    return dataToTransform\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b45f69d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "toTrainModel = makeOnlyAttackOrNot(toTrainModel)\n",
    "allDatasetToTest = makeOnlyAttackOrNot(allDatasetToTest)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb8d8751",
   "metadata": {},
   "outputs": [],
   "source": [
    "def removeNanInf(data):\n",
    "    maxNonInf = data.max().loc[lambda value: value < np.Inf].max()\n",
    "    data = data.replace(np.nan, 0)\n",
    "    data = data.replace(np.inf, maxNonInf)\n",
    "    return data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7616c18f",
   "metadata": {},
   "outputs": [],
   "source": [
    "toTrainModel = removeNanInf(toTrainModel)\n",
    "allDatasetToTest = removeNanInf(allDatasetToTest)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5beb66e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "\n",
    "# def scale(dataToTransform, columntoTransform):\n",
    "\n",
    "#     ss_dict = {col: StandardScaler() for col in columntoTransform}\n",
    "\n",
    "#     for colKey in columntoTransform:\n",
    "#         dataToTransform[colKey] = ss_dict[colKey].fit_transform(\n",
    "#             np.array(dataToTransform[colKey]).reshape(-1, 1))\n",
    "\n",
    "#     return dataToTransform\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "594ae099",
   "metadata": {},
   "outputs": [],
   "source": [
    "# numericColumntoTransform = withoutDuplicates.keys()\n",
    "# withoutDuplicates = scale(withoutDuplicates, numericColumntoTransform)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4e93444",
   "metadata": {
    "id": "xYzsVX21PFDc",
    "papermill": {
     "duration": 0.047639,
     "end_time": "2022-01-17T21:40:48.282094",
     "exception": false,
     "start_time": "2022-01-17T21:40:48.234455",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Heatmap\n",
    "#### Heatmap provide us information on how much the individual features are interpedent. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5d3cba8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-01-17T21:40:48.370987Z",
     "iopub.status.busy": "2022-01-17T21:40:48.370237Z",
     "iopub.status.idle": "2022-01-17T21:40:51.265700Z",
     "shell.execute_reply": "2022-01-17T21:40:51.266249Z",
     "shell.execute_reply.started": "2022-01-17T21:30:49.408211Z"
    },
    "id": "ObQ1AkeKPFDf",
    "papermill": {
     "duration": 2.938931,
     "end_time": "2022-01-17T21:40:51.266450",
     "exception": false,
     "start_time": "2022-01-17T21:40:48.327519",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "f, ax = plt.subplots(figsize=(15, 8))\n",
    "sns.heatmap(abs(toTrainModel.corr()), annot=True,\n",
    "            linewidths=0.5, fmt='.2f', ax=ax)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9222e1a",
   "metadata": {},
   "source": [
    "Save label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e38865a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = toTrainModel[LABEL]\n",
    "toTrainModel = toTrainModel.drop([LABEL], axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1e7b0ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "def printNanFinite(data):\n",
    "    print('Is any Nan:', np.any(np.isnan(data)))\n",
    "    print('Is all finite:', np.all(np.isfinite(data)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93c2a848",
   "metadata": {},
   "outputs": [],
   "source": [
    "printNanFinite(toTrainModel)\n",
    "print('\\n')\n",
    "printNanFinite(allDatasetToTest)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97355b3a",
   "metadata": {},
   "source": [
    "Scale numeric values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f11a5dcb",
   "metadata": {},
   "source": [
    "#### After preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4403bf33",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    toTrainModel, labels, test_size=0.33, random_state=32)\n",
    "\n",
    "\n",
    "X_train.to_csv('X_train.csv')\n",
    "X_test.to_csv('X_test.csv')\n",
    "y_train.to_csv('y_train.csv')\n",
    "y_test.to_csv('y_test.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d1f63a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "isRFC = True\n",
    "isMLPC = False\n",
    "isSequential = False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "958a0a7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "\n",
    "\n",
    "def model():\n",
    "    if isRFC:\n",
    "        model = RandomForestClassifier(\n",
    "            n_estimators=100, max_depth=5, min_samples_leaf=4)\n",
    "    elif isMLPC:\n",
    "        model = MLPClassifier(random_state=32)\n",
    "    else:\n",
    "        model = Sequential([\n",
    "            Dense(256, activation='softplus', kernel_initializer='glorot_uniform',\n",
    "                  input_dim=X_train.shape[1]),\n",
    "            Dense(128, activation='softplus',\n",
    "                  kernel_initializer='glorot_uniform'),\n",
    "            Dense(1, kernel_initializer='glorot_uniform', activation='sigmoid')\n",
    "        ])\n",
    "\n",
    "        model.compile(loss='binary_crossentropy',\n",
    "                      optimizer='Adam')\n",
    "\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a71aa012",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23f2432f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a069fe42",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "\n",
    "\n",
    "def confMatrix(yTrain, xTrainPreds, yTest, xTestPreds):\n",
    "    # Your code here\n",
    "    cmTrain = confusion_matrix(yTrain, xTrainPreds)\n",
    "    X_train_disp = ConfusionMatrixDisplay(confusion_matrix=cmTrain)\n",
    "\n",
    "    cmTest = confusion_matrix(yTest, xTestPreds)\n",
    "    X_test_disp = ConfusionMatrixDisplay(confusion_matrix=cmTest)\n",
    "    # End\n",
    "\n",
    "    _, ax = plt.subplots(1, 2, figsize=(10, 5), dpi=150)\n",
    "\n",
    "    X_train_disp.plot(ax=ax[0])\n",
    "    ax[0].set_title(\"Train\")\n",
    "\n",
    "    X_test_disp.plot(ax=ax[1])\n",
    "    ax[1].set_title(\"Test\")\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d991ff69",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score, accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "\n",
    "def printScores(name, labels, predicts):\n",
    "    print(name)\n",
    "    print('Accuracy: %.3f ' % accuracy_score(labels, predicts))\n",
    "    print('Precision: %.3f ' % precision_score(labels, predicts))\n",
    "    print('Recall: %.3f' % recall_score(labels, predicts))\n",
    "    print('F1 Score: %.3f' % f1_score(labels, predicts))\n",
    "    print('\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab898d8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "X_train_preds = model.predict(X_train)\n",
    "X_test_preds = model.predict(X_test)\n",
    "\n",
    "if isSequential:\n",
    "    print('Train auc:', roc_auc_score(y_train, X_train_preds))\n",
    "    print('Test auc:', roc_auc_score(y_test, X_test_preds))\n",
    "else:\n",
    "    printScores('Train:', y_train, X_train_preds)\n",
    "    printScores('Test:', y_test, X_test_preds)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1a07fb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "confMatrix(y_train, X_train_preds, y_test, X_test_preds)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8def0c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "allDatasetLabels = allDatasetToTest[LABEL]\n",
    "allDatasetToTest = allDatasetToTest.drop([LABEL], axis=1)\n",
    "\n",
    "allDatasetLabels.to_csv('allDatasetLabels.csv')\n",
    "allDatasetToTest.to_csv('allDatasetToTest.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14299dee",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "AllDatasetPreds = model.predict(allDatasetToTest)\n",
    "\n",
    "if isSequential:\n",
    "    print('Auc:', roc_auc_score(allDatasetLabels, AllDatasetPreds))\n",
    "else:\n",
    "    printScores('All dataset:', allDatasetLabels, AllDatasetPreds)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c57150c",
   "metadata": {},
   "outputs": [],
   "source": [
    "allDatasetConfusionMatrix = confusion_matrix(allDatasetLabels, AllDatasetPreds)\n",
    "allDataSetMatrixDisplay = ConfusionMatrixDisplay(\n",
    "    confusion_matrix=allDatasetConfusionMatrix)\n",
    "_, ax = plt.subplots(figsize=(8, 4), dpi=130)\n",
    "ax.set_title(\"All dataset\")\n",
    "allDataSetMatrixDisplay.plot(ax=ax)\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 42.965214,
   "end_time": "2022-01-17T21:41:16.495863",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2022-01-17T21:40:33.530649",
   "version": "2.3.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
